# Event-Triggered Privacy Anchors (ETPA) for Federated Learning

## ğŸ“Œ Project Overview
This project implements **Federated Learning with Differential Privacy (DP)** using two key ideas:

- **Privacy Anchors** â†’ Synthetic samples generated via DP-VAE / DP-GAN  
- **Event-Triggered Adaptation** â†’ Dynamically adjusting DP noise and regenerating anchors when client models diverge  

The aim is to achieve the right balance between **accuracy, privacy, and efficiency** in non-IID federated learning setups.

---

## âš™ï¸ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/JoyBiswas1403/etpa-fl.git
cd etpa-fl

### 2. Setup Virtual Environment
```bash
python -m venv .venv
Windows (PowerShell):

```bash
.venv\Scripts\Activate.ps1
Linux/Mac:

```bash
source .venv/bin/activate

### 3. Install Dependencies
```bash

pip install --upgrade pip
pip install -r requirements.txt

--- 

ğŸ“‚ Repository Structure

```bash
etpa-fl/
â”œâ”€â”€ client/          # Client-side training logic
â”œâ”€â”€ server/          # Server aggregation and coordination
â”œâ”€â”€ utils/           # Data partitioning, evaluation, helper functions
â”œâ”€â”€ anchors/         # Privacy Anchor generation (DP-VAE, DP-GAN)
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ README.md        # Project documentation
â””â”€â”€ main.py          # Entry point

--- 

##ğŸš€ Usage

###Run Full Federated Learning (Server + Clients)
```bash

python main.py
You should see:

```arduino

Starting Event-Triggered Privacy Anchors (ETPA) Simulation
Server is running and waiting for clients...
Client 1 is running...
Client 2 is running...
...

---

###ğŸ“Š Results & Goals

- Balance between accuracy, privacy, and efficiency
- Evaluate under non-IID data distributions
- Compare against standard DP techniques

---